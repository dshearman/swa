```{r setup, include=FALSE}
opts_chunk$set(fig.path='figure/events-events-')
opts_chunk$set(dev = 'pdf', fig.cap="")
```


### Testing for Impact 

Twitter could be regarded as information about the \alert{buzz} surrounding
a product, brand or service. 

For example, a large number of tweets about a new phone may indicate a lot of interest in that phone.

Of course, this may be negative or positive \alert{interest}. Sentiment will be discussed in another lecture.

In this lecture, we focus on the impact of an intervention, For example, 

* Does an advertising campaign produce a \alert{buzz} about a product?
* Does a product release by a competitor, decrease interest in our product?
* Does an external event, affect the tweet stream about our brand?

# Comparing Tweet rates

### What is an impact?

For the purposes of this unit we think of an impact as a change in tweet rates caused by some event.

Events might be planned or unplanned, but they are chosen externally to the tweet data.

That is, we \alert{don't} look for a change in tweet rate and then test it. This would be a biased approach.

As far as the event is concerned we need to think about \alert{before} and \alert{after} the event and compare (usually) tweet rates.

Obviously, this is applicable to Facebook like rates and reach, before and after an event

### What do we compare?

Tweet rates are one obvious thing to compare.

In detail this means the number of tweets returned by a particular search in a fixed period of time.

For example, 

* the number of tweets with the hashtag #iphone after the release of a new model may increase.
* the number of tweets may decrease when a competitor releases a new model.


### Example: Optophone Mobile Company

The Optophone Mobile Company, is going to revamp its website. In order
to justify the expense they will monitor the hit rate on the website
before and after the switch-over to the new site. Additionally, they
try to assess the buzz around their product they will also monitor the
number tweets \alert{referring to the company}.

\pause

They collect the number of tweets (ignoring sentiment) for five
randomly chosen days before the switch-over and five randomly chosen
days shortly after the switch-over.

\pause

The following counts were obtained.

\begin{center}
```{r echo=FALSE, results="asis"}
options(scipen=1, digits=2)
suppressWarnings(require(xtable, quietly=TRUE))
set.seed(56223)
n = 5
before = rpois(n, 140)
after = rpois(n, 175)
mm = rbind(before, after)
dimnames(mm) = list(c("Before", "After"), paste("day", 1:n))
print(xtable(mm, digits=0), floating=FALSE, comment=FALSE, booktabs=TRUE)
```
\end{center}

\pause

Has the website switch over had an impact on tweet rate?

### Difference in means

```{r include=FALSE}
mb = mean(before)
ma = mean(after)
```

The average number of tweets is `r mb` before and `r ma` after, giving
a difference in sample means of `r ma - mb`, so it \alert{looks} like
an increase.

But could this have occurred by chance? Or how \alert{likely} is it to
have occurred by chance?

\pause

That is, what is the chance that even if the true underlying tweet
rates were the same before and after, we could see a mean after, this
much larger than the mean before?

If this chance is small, we could argue that its likely that the
underlying tweet rate has changed.

\pause

To observe the probability of this difference in sample means
happening by chance when the population means are equal ($p$-value), we must
examine the distribution of the \alert{difference in sample means},
given that the population means are equal ($H_0$).

### Thinking about the randomisation distribution

Our hypotheses are:

- $H_0$: there is no difference in population means ($\mu_B = \mu_A$).
- $H_A$: there is a difference in population means ($\mu_B \ne \mu_A$).

We want to identify what the difference in sample means can be, if the
population means are equal. To do so, we build a randomisation
distribution of \alert{differences in sample means}.

\pause

If we assume $H_0$, then:

- both the before and after sample have the same population mean.
- we can combine the before and after sample to obtain a larger sample
  with the same population mean.
- if we randomly split the combined sample into two piles, each will
  have the same population mean.

### Creating the randomisation distribution

To create the randomisation distribution:

1. Combine the two samples into a combined sample.
2. Randomly divide the combined sample into two samples, each with the
   same size as the original samples.
3. Compute the difference in means of the two new samples.
4. Repeat at least 1000 times to obtain 1000 difference in mean values
   and examine the distribution.


```{r echo=FALSE}
library(ggplot2, quietly=TRUE)

both = c(before, after)
randDist = replicate(10000, {
pos1 = sample(10, 5, replace = FALSE)
pos2 = (1:10)[-pos1]
mean(both[pos1]) - mean(both[pos2])})
mu0 = mean(before) - mean(after)
pVal = mean(abs(randDist) > abs(mu0))
```

### Randomisation distribution

The difference in the sample means of the data is `r ma - mb`. Could
this have happened by chance if the population means are equal?

```{r echo=FALSE, fig.width=4.2, fig.height=2.5, fig.cap="Distribution of difference in sample means."}
qplot(randDist,geom="histogram",binwidth=5) + theme_grey(base_size = 10) + theme(legend.position = "none") + xlab("Difference in sample means")
#hist(h, main = "")
```

### Test conclusion

Since it is not likely that the population means are equal (the $p$
value is `r pVal`), we reject $H_0$. We have evidence of a difference
in population means.

The changes to the Optophone Web site has lead to an increase in the
number of tweets about Optophone.




###  Commonpoverty Bank
```{r include=FALSE}
set.seed(86755)
n = 4
BIx = rpois(n, 96)
AIx = rpois(n, 129)
BCx = rpois(n, 52)
ACx = rpois(n, 85)
```

#### Problem

The Commonpoverty Bank is starting an advertising campaign. They
believe that the Twitter buzz around the campaign may be a lead
indicator to increased sales of mortgages.

They decide to collect data before and after the campaign on the
number of tweets per day relating to their bank.

\begin{center}
```{r results="asis", echo=FALSE}
mm = rbind(BIx, AIx)
dimnames(mm) = list(c("Before", "After"), paste("day", 1:n))
print(xtable(mm, digits=0), floating=FALSE, comment=FALSE, booktabs=TRUE)
```
\end{center}

1. Compute the sample difference in means.
2. Show how to compute one value of the randomisation distribution.


### Commonpoverty Bank

#### Problem (continued)

```{r echo=FALSE}
library(ggplot2, quietly=TRUE)

both = c(BIx, AIx)
n = length(both)
randDist = replicate(10000, {
pos1 = sample(n, length(AIx), replace = FALSE)
pos2 = (1:n)[-pos1]
mean(both[pos1]) - mean(both[pos2])})
mu0 = mean(AIx) - mean(BIx)
pVal = mean(abs(randDist) > abs(mu0))
```

Given the following randomisation distribution for the difference in
sample means when $H_0$ is true, what is the conclusion of the test?

```{r echo=FALSE, fig.width=4.2, fig.height=2.5, fig.cap="Distribution of difference in sample means."}
qplot(randDist,geom="histogram",binwidth=4) + theme_grey(base_size = 10) + theme(legend.position = "none") + xlab("Difference in sample means")
#hist(h, main = "")
```

# Introducing a control

### Did the event cause the increase?

How do we know that the difference is due to the event?

Maybe the tweet rate increased for everyone. Or at least for people in
the same industry.

One way to get more information would be to \alert{collect tweet data
on a similar business or entity}.  Ideally, this business would not be
affected by the event, but would be affected by all other factors,
that might affect the primary business.

### Introducing a control

This type of entity is called a control. We would collect tweet
numbers \alert{before} and \alert{after} the event on both the
potentially \alert{impacted} company and the \alert{control} company.

\begin{center}
```{r echo=FALSE, results="asis"}
require(xtable, quietly=TRUE)
set.seed(56223)
n = 5
before = rpois(n, 140)
after = rpois(n, 175)
cbefore = rpois(n, 75) 
cafter = rpois(n, 75) #75)
m2 = rbind(cbefore, cafter,before, after )
mtmp = matrix(apply(m2, 1, paste, collapse=","), ncol=2)
dimnames(mtmp) = list(c("Before", "After"), c("Control", "Impact"))
print(xtable(mtmp, digits=0), floating=FALSE, comment=FALSE, booktabs=TRUE)
```

```{r echo=FALSE}
impact = c(before, after)
control = c(cbefore, cafter)
gamma0 = (mean(after) + mean(cbefore)) - (mean(before) + mean(cafter))

gammaDist = replicate(10000, {
rimpact = sample(impact)
rcontrol = sample(control)
rib = rimpact[1:n]
ria = rimpact[(n+1):(2*n)]
rcb = rcontrol[1:n]
rca = rcontrol[(n+1):(2*n)]
(mean(ria) + mean(rcb)) - (mean(rca) + mean(rib))})


aibc = c(after, cbefore)
acbi = c(cafter, before)
gamma0 = sum(aibc)/n - sum(acbi)/n
all = c(aibc,acbi)
gamma = replicate(1000, {
pos = sample(4*n, 2*n)
saibc = all[pos]
sacbi = all[-pos]
sum(saibc)/n - sum(sacbi)/n
})
pVal = mean(gamma > gamma0)


# Randomised $p$ = `r pVal`


```



\end{center}

Designs like this are used a lot in \alert{environmental} data. They
are called \alert{BACI} designs after the initial letters of
\alert{before}, \alert{after}, \alert{control}, \alert{impact}.

### Analysis of BACI designs

We assume that the sample size for each of the four cells is the same ($n$).
This simplifies the analysis, allowing us to work with the sum of the numbers in each cell.

|        | Control | Impact |
|--------|---------|--------|
| Before | BC      | BI     |
| After  | AC      | AI     |


In a BACI design;

* the difference in row totals is called a \alert{contrast for the
  before/after effect} (AC+AI) - (BC+BI)
* the difference in column totals is the \alert{contrast for the
  control/impact effect} (AI+BI) - (AC+BC)


### Analysis of BACI designs

We are not really interested in these contrasts.  They relate to the
overall change before/after and the overall difference between
companies

We are interested in whether the impacted company after, can be
predicted as simply the combination of difference between companies
and the before/after difference.

If it \alert{cannot} then the there is an effect that cannot be
explained by either the change in time or company, so the event has
had an impact

### Analysis of BACI designs

Mathematically we can write this as

|        | Control     | Impact                          |
|--------|-------------|---------------------------------|
| Before | $\mu$       | $\mu + \alpha$                  |
| After  | $\mu+\beta$ | $\mu + \alpha + \beta + \gamma$ |

- $\alpha$ is the effect caused by the change in company
- $\beta$ is the effect caused by the change in time
- $\gamma$ is the effect that cannot be explained by either time or
  change in company. If $\gamma$ is not zero, then the event we are
  examining \alert{has} had an effect.

Does $\gamma = 0$?

We use a contrast in estimating $\gamma$. Interaction contrast is
(BC+AI) - (AC+BI) (difference in diagonals), since ($\mu$ + $\mu +
\alpha + \beta + \gamma$) - ($\mu + \alpha$ + $\mu + \beta$) =
$\gamma$.

### Analysis of BACI designs

Using the contrasts, we can estimate the parameters $\alpha$, $\beta$
and $\gamma$.

Contrasts

* before/after --- (AC+AI) - (BC+BI) 
* companies --- (AI+BI) - (AC+BC)
* interaction --- (BC+AI) - (AC+BI)

Our sample estimates are given as the contrast/$2n$.

- $a = (\text{(AI+BI) - (AC+BC)})/2n$, estimate of $\alpha$
- $b = (\text{(AC+AI) - (BC+BI)})/2n$, estimate of $\beta$
- $c = (\text{(BC+AI) - (AC+BI)})/2n$, estimate of $\gamma$

### Hypothesis Test for $\gamma$

We have an estimate $c$ of $\gamma$, we must ask \alert{what is the
probability of obtaining $c$, given that $\gamma = 0$}? If $\gamma = 0$, then our event has
had no effect. If $\gamma \ne 0$, then our event has had an effect.

Our hypotheses are:

- $H_0$: $\gamma = 0$, the event has had no effect.
- $H_A$: $\gamma \ne 0$, the event has had an effect.

\pause

So under the Null Hypothesis, we have:

|        | Control     | Impact                 |
|--------|-------------|------------------------|
| Before | $\mu$       | $\mu + \alpha$         |
| After  | $\mu+\beta$ | $\mu + \alpha + \beta$ |


Residual error $\varepsilon$ (difference between the data and the
model) have the usual assumptions of Normality, constant variance and
independence.

### Test statistic and distribution

How large does $c$ have to be for us to have evidence that $\gamma \ne 0$?

We must examine the distribution $\Gamma$, the distribution of $c$
when $\gamma = 0$.

- If the $c$ computed from our data looks like it could have been
  sampled from $\Gamma$, then we cannot say that $\gamma \ne 0$.

- If the $c$ computed from our data looks like it could not have been
  sampled from $\Gamma$, then we have evidence that $\gamma \ne 0$.

But how can we compute this distribution?

\pause

We must use randomisation to simulate $\gamma = 0$.

### Randomisation distribution

Remember that the residuals error $\varepsilon$ (difference between
the data and the model) are assumed to be Normal, have constant
variance and independence.

Therefore, we can remove the residuals from the data, shuffle them,
then reattach them without effecting the distribution of the data, as
long as $\gamma = 0$.

The randomisation process is:

1. Shuffle the residuals
2. Add them back on to the fitted values to obtain new sample data.
3. Compute $c$ from the new sample data

Repeat this at least 1000 times to obtain the distribution of $c$ when $\gamma = 0$.


### Computing the randomisation distribution

#### Example

Given the below sample, we compute the statistics $m = 2.83$, $a = 2$,
$b = 3$ to obtain the expected values.

\begin{center}
\begin{tabular}{lcc}
\toprule
& Control & Impact \\
\midrule
Before & 4, 0, 3 & 8, 2, 6  \\
After  & 3, 8, 8 & 11, 3, 8 \\
\bottomrule
\end{tabular}
$\rightarrow$
\begin{tabular}{lcc}
\toprule
& Expect Control & Expect Impact \\
\midrule
Before & 2.83, 2.83, 2.83 & 4.83, 4.83, 4.83 \\
After  & 5.83, 5.83, 5.83 & 7.83, 7.83, 7.83 \\
\bottomrule
\end{tabular}
\end{center}

Giving the sets of residuals.

|        | Resid Control     | Resid Impact      |
|--------|-------------------|-------------------|
| Before | 1.17, -2.83, 0.17 | 3.17, -2.83, 1.17 |
| After  | -2.83, 2.17, 2.17 | 3.17, -4.83, 0.17 |

### Permuted residuals

#### Example

We permute the residuals.

\begin{center}
\begin{tabular}{lcc}
\toprule
& Control & Impact \\
\midrule
Before & 1.17,  -2.83, 2.17 & 2.17, 0.17, -2.83 \\
After & 3.17, -4.83, 3.17 & 0.17, 1.17, -2.83 \\
\bottomrule
\end{tabular}
\end{center}

and add them back on to the fitted model to obtain new data where $\gamma = 0$.

\begin{center}
\begin{tabular}{lcc}
\toprule
& Control & Impact \\
\midrule
Before & 4, 0, 5 & 7, 5, 2 \\
After & 9, 1, 9 & 8, 9, 5 \\
\bottomrule
\end{tabular}
\end{center}

Then compute the $c$ (sample interaction) from the new data.
If we repeat this at least 1000 times, we will obtain a distribution
of $c$, when $\gamma = 0$.

### Randomisation distribution of $c$, when $\gamma = 0$

#### Example

```{r echo=FALSE}
suppressWarnings(library(dae, quietly=TRUE))

n = 3
xs = c(4, 0, 3, 3, 8, 8, 8, 2, 6, 11, 3, 8)
when = factor(c(rep("before", n), rep("after", n), rep("before", n),
       rep("after", n)), levels = c("before", "after"))
company = factor(c(rep("control", 2 * n), rep("impact", 2 * n)),
	levels = c("control","impact"))

m = aov(xs ~ when + company)
f = predict(m)

### compute residuals
r = residuals(m)

### permute residuals and replace
R = 1000
gSet = rep(0,R)
for (m in 1:R) {
    y = f + sample(r)
    gSet[m] = yates.effects(aov(y ~ when * company))[3]
}

gVal = yates.effects(aov(xs ~ when * company))[3]
pVal = mean(abs(gSet) > abs(gVal))
```

```{r echo=FALSE, fig.width=4.2, fig.height=2.5, fig.cap="Distribution of sample interaction."}
qplot(gSet,geom="histogram",binwidth=1) + theme_grey(base_size = 10) + theme(legend.position = "none") + xlab("Sample interaction (c)")
```

### Test conclusion

#### Example

Since the alternative ($H_A$) is $\gamma \ne 0$, the test is two sided
(both positive and negative sides).

If the interaction from the data is $c = `r gVal`$, we get a $p$ value
of `r pVal`, so we do not reject $H_0$.


### Randomisation algorithm

```{r eval=TRUE}
# Setup the data
count = c(4, 0, 3, 3, 8, 8, 8, 2, 6, 11, 3, 8)
n = 3
when = factor(c(rep("before", n), rep("after", n), rep("before", n),
       rep("after", n)), levels = c("before", "after"))
company = factor(c(rep("control", 2 * n), rep("impact", 2 * n)),
	levels = c("control","impact"))

X = data.frame(when = when, company = company, count = count)
print(X)
```

### Randomisation algorithm continued

```{r eval=FALSE}
library(dae) # for yates.effects()

m = aov(count ~ when + company, data = X) # fit the Null model (no gamma)
f = predict(m)   # computed expected values
r = residuals(m) # compute residuals

### permute residuals and replace
R = 1000
cSet = rep(0,R)
for (m in 1:R) {
    y = f + sample(r) # shuffle residuals and add to fitted
    # compute c and store in cSet
    cSet[m] = yates.effects(aov(y ~ when * company, data = X))[3]
}
# compute c from data
cVal = yates.effects(aov(count ~ when * company, data = X))[3]
# compute p value
pVal = mean(abs(cSet) > abs(cVal))
```




### Back to our data

#### Problem

\begin{center}
```{r echo=FALSE, results="asis"}
print(xtable(mtmp, digits=0), floating=FALSE, comment=FALSE, booktabs=TRUE)
```
\end{center}


Compute the estimates of $\alpha$, $\beta$ and $\gamma$.

### Concluding the test

#### Problem

Based on the estimate of $\alpha$, $\beta$ and $\gamma$ and the
below distribution of $c$, given $\gamma = 0$, what is the conclusion
of the test?


```{r echo=FALSE}
n = 5
xs = c(cbefore, cafter, before, after)
when = factor(c(rep("before", n), rep("after", n), rep("before", n),
       rep("after", n)), levels = c("before", "after"))
company = factor(c(rep("control", 2 * n), rep("impact", 2 * n)),
	levels = c("control","impact"))

m = aov(xs ~ when + company)
f = predict(m)

### compute residuals
r = residuals(m)

### permute residuals and replace
R = 1000
gSet = rep(0,R)
for (m in 1:R) {
    y = f + sample(r)
    gSet[m] = yates.effects(aov(y ~ when * company))[3]
}

gVal = yates.effects(aov(xs ~ when * company))[3]
pVal = mean(abs(gSet) > abs(gVal))
```

```{r echo=FALSE, fig.width=4.2, fig.height=2.5, fig.cap="Distribution of sample interaction."}
qplot(gSet,geom="histogram",binwidth=1) + theme_grey(base_size = 10) + theme(legend.position = "none") + xlab("Sample interaction (c)")
```



### Summary

- We can test the impact of an event by counting the number of tweets
  that mention it.

- By collecting tweets before and after the event, we can test if the
  difference in mean tweet count is zero. If it is not zero, the event
  has had an impact.

- By introducing a control, we are able to identify if actual event
  lead to the change in tweet counts.

- We also saw how to obtain a randomisation distribution by
  shuffling residuals.


### Next Week

Sentiment Analysis
